{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "2021-10-19-Intro-MapReduce.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pstorniolo/Master2021/blob/main/2021_10_19_Intro_MapReduce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXjJgeiLMY8M"
      },
      "source": [
        "\n",
        "# Intro-MapReduce\n",
        "\n",
        "## Sommario\n",
        "\n",
        "1. Richiami di *functional programming* in Python\n",
        "2. Python `map` e `reduce` functions\n",
        "3. Scrittura di codice parallelo con l'uso di `map`\n",
        "4. Il modello completo di programmazione Map-Reduce\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiQDcvNUMY8N"
      },
      "source": [
        "## Programmazione Funzionale\n",
        "\n",
        "Consideriamo il seguente codice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJL1NubHMY8O"
      },
      "source": [
        "def double_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(2 * i)\n",
        "    return result\n",
        "\n",
        "def quadruple_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(4 * i)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5o_whA7MY8Q"
      },
      "source": [
        "double_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V8ZeY4JMY8S"
      },
      "source": [
        "quadruple_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxV7Ob0KMY8U"
      },
      "source": [
        "### DRY (do not repeat yourself) - Concetto fondamentale nella programmazione\n",
        "\n",
        "- Il codice precedente viola il principio [\"non ripeterti\"](https://en.wikipedia.org/wiki/Don't_repeat_yourself_) della buona pratica di ingegneria del software.\n",
        "\n",
        "- Come si può riscrivere il codice in modo che eviti la duplicazione?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRNqiA8OMY8U"
      },
      "source": [
        "def multiply_by_x_everything_in(x, data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(x * i)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz0s_8FrMY8V"
      },
      "source": [
        "multiply_by_x_everything_in(2, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmZQ1tP9MY8V"
      },
      "source": [
        "multiply_by_x_everything_in(4, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbYwhvhYMY8W"
      },
      "source": [
        "- Adesso consideriamo il seguente codice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umsml7RPMY8W"
      },
      "source": [
        "def squared(x):\n",
        "    return x*x\n",
        "\n",
        "def double(x):\n",
        "    return x*2\n",
        "\n",
        "def square_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(squared(i))\n",
        "    return result\n",
        "\n",
        "def double_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(double(i))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVOsSKoFMY8W"
      },
      "source": [
        "square_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThoFJa_RMY8X"
      },
      "source": [
        "double_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5o3uM7YMY8X"
      },
      "source": [
        "### DRY (do not repeat yourself) - Concetto fondamentale nella programmazione\n",
        "\n",
        "- Il codice precedente viola il principio [\"non ripeterti\"](https://en.wikipedia.org/wiki/Don't_repeat_yourself_) della buona pratica di ingegneria del software.\n",
        "\n",
        "- Come si può riscrivere il codice in modo che eviti la duplicazione?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVViTfvCMY8X"
      },
      "source": [
        "### Passaggio di valori ad una funzione\n",
        "- Le funzioni possono essere passate ad altre funzioni come valori.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki9R_twEMY8Y"
      },
      "source": [
        "def apply_f_to_everything_in(f, data):\n",
        "    result = []\n",
        "    for x in data:\n",
        "        result.append(f(x))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJlH223ZMY8Y"
      },
      "source": [
        "apply_f_to_everything_in(squared, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxRp-WztMY8Z"
      },
      "source": [
        "apply_f_to_everything_in(double, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgBPEBX_MY8Z"
      },
      "source": [
        "### Espressioni Lambda\n",
        "\n",
        "- Possiamo usare funzioni anonime per evitare di dover definire una funzione ogni volta che vogliamo usare map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQVOy2_pMY8a"
      },
      "source": [
        "apply_f_to_everything_in(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDdrGY5BMY8a"
      },
      "source": [
        "## La funzione `map`\n",
        "\n",
        "- Python ha una funzione integrata `map` che è molto più veloce della nostra versione.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os4rC1Q3MY8a"
      },
      "source": [
        "map(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nI_vo2zMY8b"
      },
      "source": [
        "## Implementazione di *reduce*\n",
        "\n",
        "- La funzione `reduce` è un esempio di [fold](https://en.wikipedia.org/wiki/Fold_%28higher-order_function%29) *(reduce, accumulate, aggregate, compress, or inject)*.\n",
        "\n",
        "- Ci sono diversi modi in cui possiamo effettuare il *fold* sui dati.\n",
        "\n",
        "- Quanto segue implementa un *fold a sinistra*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3zex1XyMY8b"
      },
      "source": [
        "def foldl(f, data, z):\n",
        "    if (len(data) == 0):\n",
        "        print (z)\n",
        "        return z\n",
        "    else:\n",
        "        head = data[0]\n",
        "        tail = data[1:]\n",
        "        print (\"Folding\", head, \"with\", tail, \"using\", z)\n",
        "        partial_result = f(z, data[0])\n",
        "        print (\"Partial result is\", partial_result)\n",
        "        return foldl(f, tail, partial_result)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4H47rAHMY8b"
      },
      "source": [
        "def add(x, y):\n",
        "    return x + y\n",
        "\n",
        "foldl(add, [3, 3, 3, 3, 3], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iXTuO_0MY8b"
      },
      "source": [
        "foldl(lambda x, y: x + y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4loH_aMMY8c"
      },
      "source": [
        "foldl(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CeOidepMY8c"
      },
      "source": [
        "(((((0 - 1) - 2) - 3) - 4) - 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E70SrBbgMY8c"
      },
      "source": [
        "- La sottrazione non è né [commutativa](https://en.wikipedia.org/wiki/Commutative_property) né [associativa](https://en.wikipedia.org/wiki/Associative_property), quindi l'ordine in cui si applica il *fold* è determinante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El-goJOaMY8c"
      },
      "source": [
        "(1 - (2 - (3 - (4 - (5 - 0)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4DozIRRMY8c"
      },
      "source": [
        "def foldr(f, data, z):\n",
        "    if (len(data) == 0):\n",
        "        return z\n",
        "    else:\n",
        "        return f(data[0], foldr(f, data[1:], z))                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8oBzyUEMY8c"
      },
      "source": [
        "foldl(lambda x, y: x - y,  [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Js5iBT1MY8d"
      },
      "source": [
        "foldr(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN6a5bU0MY8d"
      },
      "source": [
        "## La funzione `reduce` di Python.\n",
        "\n",
        "- La funzione `reduce` incorporata in Python è una *fold sinistra*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_j2TllMY8d"
      },
      "source": [
        "from functools import reduce\n",
        "reduce(lambda x, y: x + y, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLj19MuwMY8d"
      },
      "source": [
        "reduce(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3LxZwe4MY8e"
      },
      "source": [
        "foldl(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryyJQSQyMY8e"
      },
      "source": [
        "## Programmazione funzionale e parallelismo\n",
        "\n",
        "- La programmazione funzionale si presta alla [programmazione parallela](https://computing.llnl.gov/tutorials/parallel_comp/#Models).\n",
        "\n",
        "- La funzione `map` può essere facilmente parallelizzata tramite [parallelismo a livello di dati](https://en.wikipedia.org/wiki/Data_parallelism),\n",
        "     - a condizione che la funzione che forniamo come argomento sia *libera da* [effetti collaterali](https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29)\n",
        "         - (ecco perché evitiamo di lavorare con dati mutevoli).\n",
        "\n",
        "- Possiamo vederlo riscrivendo il codice così:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlz-eHOuMY8e"
      },
      "source": [
        "def perform_computation(f, result, data, i):\n",
        "    print (\"Computing the \", i, \"th result...\")\n",
        "    # This could be scheduled on a different CPU\n",
        "    result[i] = f(data[i])\n",
        "\n",
        "def my_map(f, data):\n",
        "    result = [None] * len(data)\n",
        "    for i in range(len(data)):\n",
        "        perform_computation(f, result, data, i)\n",
        "    # Wait for other CPUs to finish, and then..\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZ4KKTQMY8e"
      },
      "source": [
        "my_map(lambda x: x * x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8mXU-kmMY8e"
      },
      "source": [
        "## Una funzione `map` multi-thread"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwZtCFCMY8f"
      },
      "source": [
        "from threading import Thread\n",
        "\n",
        "def schedule_computation_threaded(f, result, data, threads, i):    \n",
        "    # Each function evaluation is scheduled on a different core.\n",
        "    def my_job(): \n",
        "        print (\"Processing data:\", data[i], \"... \")\n",
        "        result[i] = f(data[i])\n",
        "        print (\"Finished job #\", i)    \n",
        "        print (\"Result was\", result[i])       \n",
        "    threads[i] = Thread(target=my_job)\n",
        "    \n",
        "def my_map_multithreaded(f, data):\n",
        "    n = len(data)\n",
        "    result = [None] * n\n",
        "    threads = [None] * n\n",
        "    print (\"Scheduling jobs.. \")\n",
        "    for i in range(n):\n",
        "        schedule_computation_threaded(f, result, data, threads, i)\n",
        "    print (\"Starting jobs.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].start()\n",
        "    print (\"Waiting for jobs to finish.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    print (\"All done.\")\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JqCWCEoMY8f"
      },
      "source": [
        "my_map_multithreaded(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-pLDOngMY8f"
      },
      "source": [
        "from numpy.random import uniform\n",
        "from time import sleep\n",
        "\n",
        "def a_function_which_takes_a_long_time(x):\n",
        "    sleep(uniform(2, 10))  # Simulate some long computation\n",
        "    return x*x\n",
        "\n",
        "my_map_multithreaded(a_function_which_takes_a_long_time, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72j61kokMY8f"
      },
      "source": [
        "## Map Reduce\n",
        "\n",
        "- Map Reduce è un _modello di programmazione_ per l'elaborazione parallela scalabile.\n",
        "- Scalabile qui significa che può funzionare su big data con cluster di calcolo molto grandi.\n",
        "- Ci sono molte implementazioni: ad es. Apache Hadoop e Apache Spark.\n",
        "- Possiamo utilizzare Map-Reduce con qualsiasi linguaggio di programmazione:\n",
        "     - Hadoop è scritto in Java\n",
        "     - Spark è scritto in Scala, ma ha un'interfaccia Python.\n",
        "- Linguaggi di *programmazione funzionale* come Python o Scala si adattano molto bene al modello Map Reduce:\n",
        "     - Tuttavia, non *dobbiamo* usare la programmazione funzionale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzALz6_-MY8g"
      },
      "source": [
        "- Un'implementazione di MapReduce si occuperà delle funzionalità di basso livello in modo che non ci si debba preoccupare di:\n",
        "     - bilancio del carico\n",
        "     - I/O di rete\n",
        "     - ottimizzazione del trasferimento di rete e su disco\n",
        "     - gestione guasti macchina\n",
        "     - serializzazione dei dati\n",
        "     - eccetera..\n",
        "- Il modello è progettato per spostare l'elaborazione nel luogo in cui risiedono i dati."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HulVngL_MY8g"
      },
      "source": [
        "## Passaggi tipici in un calcolo Map-Reduce\n",
        "\n",
        "1. ETL un grande set di dati.\n",
        "2. Operazione _Map_: estrai qualcosa che ti interessa da ogni riga\n",
        "3. \"Shuffle and Sort\": allocazione task/nodo\n",
        "4. Operazione _Riduci_: aggrega, riepiloga, filtra o trasforma\n",
        "5. Scrivi i risultati."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQDDnWoJMY8g"
      },
      "source": [
        "## Callback per Map Reduce\n",
        "\n",
        "- Il set di dati e lo stato di ogni fase del calcolo è rappresentato come un insieme di coppie chiave-valore.\n",
        "\n",
        "- Il programmatore fornisce una funzione mappa:\n",
        "\n",
        "  $\\operatorname{map}(k, v) \\rightarrow \\; \\left< k', v' \\right>*$\n",
        "\n",
        "- e una funzione di riduzione:\n",
        "\n",
        "  $\\operatorname{reduce}(k', \\left< k', v'\\right> *) \\rightarrow \\; \\left< k', v''\n",
        "\\right> *$\n",
        "\n",
        "- Indicando con $*$ una *raccolta* di valori.\n",
        "\n",
        "- Queste raccolte *non* sono ordinate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQmdVrnVMY8g"
      },
      "source": [
        "## Esempio di conteggio parole\n",
        "\n",
        "- In questo semplice esempio, l'input è un insieme di URL, ogni record è un documento.\n",
        "\n",
        "- Problema: calcola quante volte ogni parola si è presentata nel set di dati."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6CYu3zhMY8h"
      },
      "source": [
        "## Conteggio parole: mappa\n",
        "\n",
        "\n",
        "- L'input di $\\operatorname{map}$ è una mappatura:\n",
        "\n",
        "  - Chiave: URL\n",
        "  - Valore: contenuto del documento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4YXCsl-MY8h"
      },
      "source": [
        "$\\left< document1, to \\; be \\; or \\; not \\; to \\; be \\right>$      \n",
        "\n",
        "- In questo esempio, la nostra funzione $\\operatorname{map}$ elaborerà un determinato URL e produrrà una mappatura:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1W3oNMkMY8h"
      },
      "source": [
        "- Key: parola\n",
        "- Value: 1\n",
        "\n",
        "- Quindi il nostro set di dati originale sarà trasformato in:\n",
        "  \n",
        "  $\\left< to, 1 \\right>$\n",
        "  $\\left< be, 1 \\right>$\n",
        "  $\\left< or, 1 \\right>$\n",
        "  $\\left< not, 1 \\right>$\n",
        "  $\\left< to, 1 \\right>$\n",
        "  $\\left< be, 1 \\right>$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exg6vxurMY8h"
      },
      "source": [
        "## Conteggio parole: Reduce\n",
        "\n",
        "\n",
        "- L'operazione di riduzione raggruppa i valori in base alla loro chiave, quindi esegue l'operazione di riduzione su ogni chiave.\n",
        "\n",
        "- Le collezioni sono quindi suddivise in diverse unità di archiviazione.\n",
        "\n",
        "- Map-Reduce effettuerà il *fold* dei dati in modo tale da ridurre al minimo la copia dei dati attraverso il cluster.\n",
        "\n",
        "- I dati in diverse partizioni vengono ridotti separatamente in parallelo.\n",
        "\n",
        "- Il risultato finale è una *reduce* dei dati in ogni partizione.\n",
        "\n",
        "- Quindi è molto importante che il nostro operatore essere *sia commutativo che associativo*.\n",
        "\n",
        "- Nel nostro caso la funzione è l'operatore `+`\n",
        "\n",
        "  $\\left< be, 2 \\right>$  \n",
        "  $\\left< not, 1 \\right>$  \n",
        "  $\\left< or, 1 \\right>$  \n",
        "  $\\left< to, 2 \\right>$  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU8VAI_XMY8h"
      },
      "source": [
        "## Map e reduce rispetto a Python\n",
        "\n",
        "- Notare che queste funzioni sono formulate in modo diverso dalle funzioni standard di Python con lo stesso nome.\n",
        "\n",
        "- La funzione `reduce` funziona con *coppie* di valori-chiave.\n",
        "\n",
        "- Sarebbe più appropriato chiamarlo qualcosa come `reduceByKey`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkYijCCcMY8i"
      },
      "source": [
        "## MiniMapReduce\n",
        "\n",
        "- Per illustrare come funziona il modello di programmazione Map-Reduce, possiamo implementare il nostro framework Map-Reduce in Python.\n",
        "\n",
        "- Questo *illustra* come un problema può essere scritto in termini di operazioni `map` e `reduce`.\n",
        "\n",
        "- Notare che queste sono funzioni illustrative; questo *non* è il modo in cui Hadoop o Apache Spark li implementano effettivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjCXlCCsMY8j"
      },
      "source": [
        "##########################################################\n",
        "#\n",
        "#   MiniMapReduce\n",
        "#\n",
        "# A non-parallel, non-scalable Map-Reduce implementation\n",
        "##########################################################\n",
        "\n",
        "def groupByKey(data):\n",
        "    result = dict()\n",
        "    for key, value in data:\n",
        "        if key in result:\n",
        "            result[key].append(value)\n",
        "        else:\n",
        "            result[key] = [value]\n",
        "    return result\n",
        "        \n",
        "def reduceByKey(f, key_values):\n",
        "    return map(lambda key: (key, reduce(f, key_values[key])), key_values.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRPdXoDXMY8k"
      },
      "source": [
        "## Conteggio parole utilizzando MiniMapReduce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_KqrlaMMY8k"
      },
      "source": [
        "data = map(lambda x: (x, 1), \"to be or not to be\".split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD6kTxEWMY8l"
      },
      "source": [
        "key_values = groupByKey(data)\n",
        "print(key_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkmoX5dAMY8l"
      },
      "source": [
        "dict(reduceByKey(lambda x, y: x + y, key_values))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQdHA0B-MY8l"
      },
      "source": [
        "## Parallelizzare MiniMapReduce\n",
        "\n",
        "- Possiamo trasformare la nostra implementazione di Map-Reduce in un framework parallelo e multi-thread\n",
        "utilizzando la funzione `my_map_multithreaded` definita in precedenza.\n",
        "\n",
        "- Questo ci consentirà di eseguire calcoli di riduzione della mappa che sfruttano l'elaborazione parallela utilizzando *più* core su un *singolo* computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMSP5l8OMY8l"
      },
      "source": [
        "def reduceByKey_multithreaded(f, data):\n",
        "    key_values = groupByKey(data)\n",
        "    return my_map_multithreaded(lambda key: (key, reduce(f, key_values[key])), key_values.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFj7dXajMY8l"
      },
      "source": [
        "reduceByKey_multithreaded(lambda x, y: x + y, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjU_3WVeMY8m"
      },
      "source": [
        "## Parallelizzazione della fase di riduzione\n",
        "\n",
        "- A condizione che il nostro operatore sia associativo e commutativo possiamo parallelizzare anche l'operazione di riduzione.\n",
        "\n",
        "- Dividiamo i dati in sottoinsiemi approssimativamente uguali.\n",
        "\n",
        "- Quindi riduciamo ogni sottoinsieme indipendentemente su un core separato.\n",
        "\n",
        "- I risultati possono essere combinati in una fase di riduzione finale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbIaQJ_KMY8m"
      },
      "source": [
        "### Partizionamento dei dati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZrJdoj7MY8m"
      },
      "source": [
        "def split_data(data, split_points):\n",
        "    partitions = []\n",
        "    n = 0\n",
        "    for i in split_points:\n",
        "        partitions.append(data[n:i])\n",
        "        n = i\n",
        "    partitions.append(data[n:])\n",
        "    return partitions\n",
        "\n",
        "data = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
        "partitioned_data = split_data(data, [3])\n",
        "partitioned_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uq_bmvcMY8m"
      },
      "source": [
        "### Riduzione tra le partizioni in parallelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK305ygAMY8m"
      },
      "source": [
        "from threading import Thread\n",
        "\n",
        "def parallel_reduce(f, partitions):\n",
        "\n",
        "    n = len(partitions)\n",
        "    results = [None] * n\n",
        "    threads = [None] * n\n",
        "    \n",
        "    def job(i):\n",
        "        results[i] = reduce(f, partitions[i])\n",
        "\n",
        "    for i in range(n):\n",
        "        threads[i] = Thread(target = lambda: job(i))\n",
        "        threads[i].start()\n",
        "    \n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    \n",
        "    return reduce(f, results)\n",
        "\n",
        "parallel_reduce(lambda x, y: x + y, partitioned_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2NZRyzOMY8m"
      },
      "source": [
        "## Map-Reduce su un cluster di computer\n",
        "\n",
        "- Il codice che abbiamo scritto finora *non* ci permetterà di sfruttare il parallelismo da più computer in un [cluster](https://en.wikipedia.org/wiki/Computer_cluster).\n",
        "\n",
        "- Lo sviluppo di un tale framework sarebbe un progetto di ingegneria del software molto ampio.\n",
        "\n",
        "- Esistono framework che possiamo utilizzare:\n",
        "     - [Apache Hadoop](https://hadoop.apache.org/)\n",
        "     - [Apache Spark](https://spark.apache.org/)"
      ]
    }
  ]
}