{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-10-23-Spark_DataFrame.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S7AlbA1DuMsO"
      ],
      "authorship_tag": "ABX9TyNEgfJ0ZD743guzYZO24Ps+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pstorniolo/Master2021/blob/main/2021_10_23_Spark_DataFrame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAcoCqXdg14_"
      },
      "source": [
        "#DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz8R62ztbWw8",
        "outputId": "15891066-70a6-4419-d749-e97e61a552d9"
      },
      "source": [
        "# Install Spark 3.2.0\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!rm -f *.tgz*\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\"\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install -q pyspark==3.2.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 36 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 13.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbD0ukPubXws"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "\n",
        "spark=SparkSession.builder.appName(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1ZcPaOne3hO"
      },
      "source": [
        "##Create a PySpark DataFrame from a list of rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYXt54f2cifh",
        "outputId": "fe0d0e5f-f151-4e1b-c97c-c750e1b0494c"
      },
      "source": [
        "df = spark.createDataFrame([\n",
        "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
        "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
        "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
        "])\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOKAC5M-fOL7"
      },
      "source": [
        "##Create a PySpark DataFrame with an explicit schema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgzh54qqfVl1",
        "outputId": "4da4702c-9413-47d8-e522-bc3ef56ee23d"
      },
      "source": [
        "df = spark.createDataFrame([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "], schema='a long, b double, c string, d date, e timestamp')\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo3Hfu_egYQ0"
      },
      "source": [
        "##Create a PySpark DataFrame from a pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2dprCFHchHB",
        "outputId": "2da411d6-20ef-4150-a0ce-f0290a34fe0d"
      },
      "source": [
        "pandas_df = pd.DataFrame({\n",
        "    'a': [1, 2, 3],\n",
        "    'b': [2., 3., 4.],\n",
        "    'c': ['string1', 'string2', 'string3'],\n",
        "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
        "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
        "})\n",
        "print(pandas_df)\n",
        "\n",
        "df = spark.createDataFrame(pandas_df)\n",
        "print(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   a    b        c           d                   e\n",
            "0  1  2.0  string1  2000-01-01 2000-01-01 12:00:00\n",
            "1  2  3.0  string2  2000-02-01 2000-01-02 12:00:00\n",
            "2  3  4.0  string3  2000-03-01 2000-01-03 12:00:00\n",
            "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S_fWkJch3Ck"
      },
      "source": [
        "## Read data with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKAf0702lblY"
      },
      "source": [
        "### CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp5zT0BXh8WB",
        "outputId": "b2b2c03b-89d1-4681-ae6f-7d06ed94487d"
      },
      "source": [
        "pandas_df = pd.read_csv('sample_data/california_housing_test.csv')\n",
        "\n",
        "california_housing_df = spark.createDataFrame(pandas_df)\n",
        "\n",
        "california_housing_df.show()\n",
        "california_housing_df.printSchema()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -122.05|   37.37|              27.0|     3885.0|         661.0|    1537.0|     606.0|       6.6085|          344700.0|\n",
            "|   -118.3|   34.26|              43.0|     1510.0|         310.0|     809.0|     277.0|        3.599|          176500.0|\n",
            "|  -117.81|   33.78|              27.0|     3589.0|         507.0|    1484.0|     495.0|       5.7934|          270500.0|\n",
            "|  -118.36|   33.82|              28.0|       67.0|          15.0|      49.0|      11.0|       6.1359|          330000.0|\n",
            "|  -119.67|   36.33|              19.0|     1241.0|         244.0|     850.0|     237.0|       2.9375|           81700.0|\n",
            "|  -119.56|   36.51|              37.0|     1018.0|         213.0|     663.0|     204.0|       1.6635|           67000.0|\n",
            "|  -121.43|   38.63|              43.0|     1009.0|         225.0|     604.0|     218.0|       1.6641|           67000.0|\n",
            "|  -120.65|   35.48|              19.0|     2310.0|         471.0|    1341.0|     441.0|        3.225|          166900.0|\n",
            "|  -122.84|    38.4|              15.0|     3080.0|         617.0|    1446.0|     599.0|       3.6696|          194400.0|\n",
            "|  -118.02|   34.08|              31.0|     2402.0|         632.0|    2830.0|     603.0|       2.3333|          164200.0|\n",
            "|  -118.24|   33.98|              45.0|      972.0|         249.0|    1288.0|     261.0|       2.2054|          125000.0|\n",
            "|  -119.12|   35.85|              37.0|      736.0|         166.0|     564.0|     138.0|       2.4167|           58300.0|\n",
            "|  -121.93|   37.25|              36.0|     1089.0|         182.0|     535.0|     170.0|         4.69|          252600.0|\n",
            "|  -117.03|   32.97|              16.0|     3936.0|         694.0|    1935.0|     659.0|       4.5625|          231200.0|\n",
            "|  -117.97|   33.73|              27.0|     2097.0|         325.0|    1217.0|     331.0|       5.7121|          222500.0|\n",
            "|  -117.99|   33.81|              42.0|      161.0|          40.0|     157.0|      50.0|          2.2|          153100.0|\n",
            "|  -120.81|   37.53|              15.0|      570.0|         123.0|     189.0|     107.0|        1.875|          181300.0|\n",
            "|   -121.2|   38.69|              26.0|     3077.0|         607.0|    1603.0|     595.0|       2.7174|          137500.0|\n",
            "|  -118.88|   34.21|              26.0|     1590.0|         196.0|     654.0|     199.0|       6.5851|          300000.0|\n",
            "|  -122.59|   38.01|              35.0|     8814.0|        1307.0|    3450.0|    1258.0|       6.1724|          414300.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be8Wp8r2lkAu"
      },
      "source": [
        "###JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELqf6s39ljVf",
        "outputId": "f52c941e-7c67-4a89-8330-93a47938d980"
      },
      "source": [
        "pandas_df = pd.read_json('sample_data/anscombe.json')\n",
        "\n",
        "anscombe_df = spark.createDataFrame(pandas_df)\n",
        "anscombe_df.show()\n",
        "anscombe_df.printSchema()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+------------------+\n",
            "|Series|  X|                 Y|\n",
            "+------+---+------------------+\n",
            "|     I| 10|              8.04|\n",
            "|     I|  8|              6.95|\n",
            "|     I| 13|              7.58|\n",
            "|     I|  9|              8.81|\n",
            "|     I| 11|              8.33|\n",
            "|     I| 14|              9.96|\n",
            "|     I|  6|              7.24|\n",
            "|     I|  4|              4.26|\n",
            "|     I| 12|             10.84|\n",
            "|     I|  7|4.8100000000000005|\n",
            "|     I|  5|              5.68|\n",
            "|    II| 10|              9.14|\n",
            "|    II|  8|              8.14|\n",
            "|    II| 13|              8.74|\n",
            "|    II|  9|              8.77|\n",
            "|    II| 11|              9.26|\n",
            "|    II| 14|               8.1|\n",
            "|    II|  6|              6.13|\n",
            "|    II|  4|               3.1|\n",
            "|    II| 12|              9.13|\n",
            "+------+---+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- Series: string (nullable = true)\n",
            " |-- X: long (nullable = true)\n",
            " |-- Y: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T84OLdiipxEG",
        "outputId": "329c07a1-694f-4938-a971-3761a823e4eb"
      },
      "source": [
        "anscombe_df.show(2, vertical=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0------\n",
            " Series | I    \n",
            " X      | 10   \n",
            " Y      | 8.04 \n",
            "-RECORD 1------\n",
            " Series | I    \n",
            " X      | 8    \n",
            " Y      | 6.95 \n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB-aHwEfpzSy",
        "outputId": "82e6adbb-bcbe-450e-fd4e-099c31fe41b2"
      },
      "source": [
        "anscombe_df.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Series', 'X', 'Y']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VISOdJhGqdUN",
        "outputId": "e053170d-2c94-4f7c-8eaf-a70744c78e26"
      },
      "source": [
        "anscombe_df.take(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Series='I', X=10, Y=8.04),\n",
              " Row(Series='I', X=8, Y=6.95),\n",
              " Row(Series='I', X=13, Y=7.58)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F56PSi5q0Dr",
        "outputId": "d8ee8a51-96e8-416a-934a-ed4de6710caa"
      },
      "source": [
        "california_housing_df.take(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(longitude=-122.05, latitude=37.37, housing_median_age=27.0, total_rooms=3885.0, total_bedrooms=661.0, population=1537.0, households=606.0, median_income=6.6085, median_house_value=344700.0),\n",
              " Row(longitude=-118.3, latitude=34.26, housing_median_age=43.0, total_rooms=1510.0, total_bedrooms=310.0, population=809.0, households=277.0, median_income=3.599, median_house_value=176500.0),\n",
              " Row(longitude=-117.81, latitude=33.78, housing_median_age=27.0, total_rooms=3589.0, total_bedrooms=507.0, population=1484.0, households=495.0, median_income=5.7934, median_house_value=270500.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtZdaBh4rAhx"
      },
      "source": [
        "##Selecting and Accessing Data\n",
        "\n",
        "PySpark DataFrame viene valutato in \"modo minimale\" e la semplice selezione di una colonna non attiva un calcolo ma restituisce un'istanza di colonna.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpGbPfkuzLlO",
        "outputId": "4bb6aa8b-29f9-427e-ce22-d95da79b792f"
      },
      "source": [
        "df.a"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'a'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt5grFbDzSaR"
      },
      "source": [
        "La maggior parte delle operazioni per colonna restituisce colonne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z62WzxjxrOaO",
        "outputId": "5b110271-56a6-483a-edd3-b85c749ca90d"
      },
      "source": [
        "from pyspark.sql import Column\n",
        "from pyspark.sql.functions import upper\n",
        "\n",
        "type(df.c) == type(upper(df.c)) == type(df.c.isNull())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3TsNVSfs6In"
      },
      "source": [
        "Queste colonne possono essere utilizzate per selezionare le colonne da un DataFrame. Per esempio, **DataFrame.select()** accetta le istanze di *Column* e restituisce un altro DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiGA5IY6sVwN",
        "outputId": "187b4e7a-a5dc-4717-aa38-bd07ba8c252b"
      },
      "source": [
        "df.select(df.c).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|      c|\n",
            "+-------+\n",
            "|string1|\n",
            "|string2|\n",
            "|string3|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0JbM4XDtNDp"
      },
      "source": [
        "Assegna una nuova istanza di colonna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjEwuctqscJT",
        "outputId": "09cdbdf6-9080-4dec-d19c-1b2a33aba459"
      },
      "source": [
        "df.withColumn('upperC', upper(df.c)).show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+-------+\n",
            "|  a|  b|      c|         d|                  e| upperC|\n",
            "+---+---+-------+----------+-------------------+-------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|STRING2|\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|STRING3|\n",
            "+---+---+-------+----------+-------------------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htDsDayltRwS"
      },
      "source": [
        "Per selezionare un sottoinsieme di righe, si utilizza **DataFrame.filter()**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAQlmzmmsmm7",
        "outputId": "4b67ac3f-7c78-4a5d-e8fc-28f8c9a7c2ac"
      },
      "source": [
        "df.filter(df.a == 1).show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7AlbA1DuMsO"
      },
      "source": [
        "##Applying a Function\n",
        "\n",
        "PySpark supporta varie UDF (*user-defined function*) e API per consentire agli utenti di eseguire funzioni native di Python.L'esempio seguente consente agli utenti di utilizzare direttamente le API in una serie di panda all'interno della funzione nativa di Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GPckeYQuScj",
        "outputId": "6d730ea4-0a1f-4b0f-a593-83cdf89f6590"
      },
      "source": [
        "import pandas\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "\n",
        "@pandas_udf('long')\n",
        "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
        "    # Simply plus one by using pandas Series.\n",
        "    return series + 1\n",
        "\n",
        "df.select(pandas_plus_one(df.a)).show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|pandas_plus_one(a)|\n",
            "+------------------+\n",
            "|                 2|\n",
            "|                 3|\n",
            "|                 4|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmH78QGEuxEd"
      },
      "source": [
        "Un altro esempio è **DataFrame.mapInPandas** che consente agli utenti di utilizzare direttamente le API in un DataFrame panda senza alcuna restrizione come la lunghezza del risultato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3m78Pl8u1Hs",
        "outputId": "a7516b2d-aecc-43f8-ed9d-4c80b42451c4"
      },
      "source": [
        "def pandas_filter_func(iterator):\n",
        "    for pandas_df in iterator:\n",
        "        yield pandas_df[pandas_df.a == 1]\n",
        "\n",
        "df.mapInPandas(pandas_filter_func, schema=df.schema).show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYQh8dHBxMVl"
      },
      "source": [
        "##Grouping Data\n",
        "\n",
        "PySpark DataFrame fornisce anche un modo per gestire i dati raggruppati utilizzando l'approccio comune, la strategia *split-apply-combine*. Raggruppa i dati in base a una determinata condizione applica una funzione a ciascun gruppo e quindi li combina di nuovo al DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmH48b7IxQhR",
        "outputId": "b38afb72-4d5c-4b64-a459-281ebb472c1f"
      },
      "source": [
        "df = spark.createDataFrame([\n",
        "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
        "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
        "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], \n",
        "    schema=['color', 'fruit', 'v1', 'v2'])\n",
        "df.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "+-----+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W14mSwLc0rOw"
      },
      "source": [
        "Raggruppamento e quindi applicazione della funzione **avg()** ai gruppi risultanti."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCjKL1v600XJ",
        "outputId": "b20c2a78-d0a6-493c-f803-ef6b306c1e75"
      },
      "source": [
        "df.groupby('color').avg().show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-------+\n",
            "|color|avg(v1)|avg(v2)|\n",
            "+-----+-------+-------+\n",
            "|  red|    4.8|   48.0|\n",
            "| blue|    3.0|   30.0|\n",
            "|black|    6.0|   60.0|\n",
            "+-----+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6IddIvJ0_AS",
        "outputId": "bc1f2ae3-043e-42d5-afc5-168c9a7e19ef"
      },
      "source": [
        "df.groupby('fruit').avg().show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+------------------+\n",
            "| fruit|           avg(v1)|           avg(v2)|\n",
            "+------+------------------+------------------+\n",
            "| grape|               6.0|              60.0|\n",
            "|banana|3.3333333333333335|33.333333333333336|\n",
            "|carrot| 4.666666666666667|46.666666666666664|\n",
            "+------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUb60sZb1KkF"
      },
      "source": [
        "Si può applicare anche una funzione nativa Python a ciascun gruppo utilizzando l'API pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCRf4MYl1Wef",
        "outputId": "a38bc19e-a40e-42f5-9a8c-54b9428c8dae"
      },
      "source": [
        "def plus_mean(pandas_df):\n",
        "    return pandas_df.assign(v1=pandas_df.v1 - pandas_df.v1.mean())\n",
        "\n",
        "df.groupby('color').applyInPandas(plus_mean, schema=df.schema).show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|black|carrot|  0| 60|\n",
            "| blue|banana| -1| 20|\n",
            "| blue| grape|  1| 40|\n",
            "|  red|banana| -3| 10|\n",
            "|  red|carrot| -1| 30|\n",
            "|  red|carrot|  0| 50|\n",
            "|  red|banana|  2| 70|\n",
            "|  red| grape|  3| 80|\n",
            "+-----+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiNzptNi2Ahn"
      },
      "source": [
        "Co-raggruppamento e applicazione di una funzione.\n",
        "\n",
        "---\n",
        "`pandas.merge_asof(left, right, on=None, left_on=None, right_on=None, left_index=False, right_index=False, by=None, left_by=None, right_by=None, suffixes=('_x', '_y'), tolerance=None, allow_exact_matches=True, direction='backward')`\n",
        "\n",
        "---\n",
        "L'unione asof è simile a un left-join tranne per il fatto che abbiniamo la chiave più vicina anziché le chiavi uguali.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaTuqiqm2G2K",
        "outputId": "db8c57a1-aa25-4912-b157-501ce371b703"
      },
      "source": [
        "df1 = spark.createDataFrame(\n",
        "    [(20000101, 1, 1.0), (20000101, 2, 2.0), (20000102, 1, 3.0), (20000102, 2, 4.0)],\n",
        "    ('time', 'id', 'v1'))\n",
        "df1.show()\n",
        "\n",
        "df2 = spark.createDataFrame(\n",
        "    [(20000101, 1, 'x'), (20000101, 2, 'y')],\n",
        "    ('time', 'id', 'v2'))\n",
        "df2.show()\n",
        "\n",
        "def asof_join(l, r):\n",
        "    return pd.merge_asof(l, r, on='time', by='id')\n",
        "\n",
        "df1.groupby('id').cogroup(df2.groupby('id')).applyInPandas(\n",
        "    asof_join, schema='time int, id int, v1 double, v2 string').show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+---+\n",
            "|    time| id| v1|\n",
            "+--------+---+---+\n",
            "|20000101|  1|1.0|\n",
            "|20000101|  2|2.0|\n",
            "|20000102|  1|3.0|\n",
            "|20000102|  2|4.0|\n",
            "+--------+---+---+\n",
            "\n",
            "+--------+---+---+\n",
            "|    time| id| v2|\n",
            "+--------+---+---+\n",
            "|20000101|  1|  x|\n",
            "|20000101|  2|  y|\n",
            "+--------+---+---+\n",
            "\n",
            "+--------+---+---+---+\n",
            "|    time| id| v1| v2|\n",
            "+--------+---+---+---+\n",
            "|20000101|  1|1.0|  x|\n",
            "|20000102|  1|3.0|  x|\n",
            "|20000101|  2|2.0|  y|\n",
            "|20000102|  2|4.0|  y|\n",
            "+--------+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "XdWPzE_yHjvt",
        "outputId": "8ba598e6-e02f-4273-9537-2adccf1d8777"
      },
      "source": [
        "pandas_df = df.to_pandas_on_spark()\n",
        "pandas_df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>color</th>\n",
              "      <th>fruit</th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>red</td>\n",
              "      <td>banana</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blue</td>\n",
              "      <td>banana</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>red</td>\n",
              "      <td>carrot</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blue</td>\n",
              "      <td>grape</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>red</td>\n",
              "      <td>carrot</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>black</td>\n",
              "      <td>carrot</td>\n",
              "      <td>6</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>red</td>\n",
              "      <td>banana</td>\n",
              "      <td>7</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>red</td>\n",
              "      <td>grape</td>\n",
              "      <td>8</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   color   fruit  v1  v2\n",
              "0    red  banana   1  10\n",
              "1   blue  banana   2  20\n",
              "2    red  carrot   3  30\n",
              "3   blue   grape   4  40\n",
              "4    red  carrot   5  50\n",
              "5  black  carrot   6  60\n",
              "6    red  banana   7  70\n",
              "7    red   grape   8  80"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhREYG6H6PQU"
      },
      "source": [
        "##Getting Data in/out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqPqxcBdByfu",
        "outputId": "eb3cc692-94fd-49a3-a18d-967b5a4916a1"
      },
      "source": [
        "!rm -rf foo*\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
        "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
        "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], \n",
        "    schema=['color', 'fruit', 'v1', 'v2'])\n",
        "df.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "+-----+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tj2KCOX7f3l"
      },
      "source": [
        "###Read & Write **CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RoBsCjC6YEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daaf0b39-30f1-48cb-a8c4-d49f4837a98c"
      },
      "source": [
        "df.write.csv('foo.csv')\n",
        "spark.read.csv('foo.csv').show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---+---+\n",
            "|  _c0|   _c1|_c2|_c3|\n",
            "+-----+------+---+---+\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "+-----+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUlYcS8U79nZ"
      },
      "source": [
        "###Write & Read **Parquet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6yrIsAW7ePF",
        "outputId": "14c6f4c9-b84e-4fe5-884e-dd013930cf2b"
      },
      "source": [
        "df.write.parquet('foo.parquet')\n",
        "spark.read.parquet('foo.parquet').show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "+-----+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ4B1oW_8fZz"
      },
      "source": [
        "###Read & Write **ORC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKxN-2WE8jCl",
        "outputId": "f4cefd92-33ab-4462-cbd8-fe7966cb33b9"
      },
      "source": [
        "df.write.orc('foo.orc')\n",
        "spark.read.orc('foo.orc').show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "+-----+------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPzFvIno8zhN",
        "outputId": "1bd28885-496f-4ee2-9e23-2e0bdfea6b40"
      },
      "source": [
        "!ls -la foo*"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 165 Oct 22 17:39 foo_pandas.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vxu69eq_Cmx"
      },
      "source": [
        "##Working with SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_KOKUqU_QJE"
      },
      "source": [
        "DataFrame e Spark SQL condividono lo stesso motore di esecuzione in modo che possano essere utilizzati in modo intercambiabile senza problemi. Ad esempio, si può registrare un DataFrame come tabella ed eseguire facilmente una query SQL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9So5OrJF_GtT",
        "outputId": "cac30159-f477-49ec-db04-c1080f396b78"
      },
      "source": [
        "df.createOrReplaceTempView(\"tableA\")\n",
        "spark.sql(\"SELECT count(*) from tableA\").show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|count(1)|\n",
            "+--------+\n",
            "|       8|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qS-UU9_kNI"
      },
      "source": [
        "Inoltre, le UDF possono essere registrate e richiamate in SQL immediatamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atr4Or3L_MuW",
        "outputId": "9040fc3a-73b5-4a9c-98dc-94dd6264db0e"
      },
      "source": [
        "@pandas_udf(\"integer\")\n",
        "def add_one(s: pd.Series) -> pd.Series:\n",
        "    return s + 1\n",
        "\n",
        "spark.udf.register(\"add_one\", add_one)\n",
        "spark.sql(\"SELECT add_one(v1) FROM tableA\").show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|add_one(v1)|\n",
            "+-----------+\n",
            "|          2|\n",
            "|          3|\n",
            "|          4|\n",
            "|          5|\n",
            "|          6|\n",
            "|          7|\n",
            "|          8|\n",
            "|          9|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLxXXtic_5tO"
      },
      "source": [
        "Queste espressioni SQL possono essere mescolate direttamente e utilizzate come colonne PySpark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-c9miuY_6vs",
        "outputId": "4628ac3f-0bb6-4f2f-a524-77f6f56989fc"
      },
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "df.selectExpr('add_one(v1)').show()\n",
        "df.select(expr('count(*)') > 0).show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|add_one(v1)|\n",
            "+-----------+\n",
            "|          2|\n",
            "|          3|\n",
            "|          4|\n",
            "|          5|\n",
            "|          6|\n",
            "|          7|\n",
            "|          8|\n",
            "|          9|\n",
            "+-----------+\n",
            "\n",
            "+--------------+\n",
            "|(count(1) > 0)|\n",
            "+--------------+\n",
            "|          true|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}