{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-10-30-Spark_Examples_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMryifmDNSx7Yi5ptjLkgLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pstorniolo/Master2021/blob/main/2021_10_30_Spark_Examples_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f6H7MzVTOgK"
      },
      "source": [
        "# Install Spark 3.2.0 - JDK11\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!rm -f *.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"]  = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\"\n",
        "\n",
        "#Install findspark using pip to make pyspark importable as regular library\n",
        "!pip -q install findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Learning_Spark\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sql = spark.sql\n",
        "\n",
        "print(\"\\nApache Spark version: \", spark.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Obb-rKAPUS"
      },
      "source": [
        "https://spark.apache.org/docs/latest/sql-programming-guide.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSFa9ihZUdzQ"
      },
      "source": [
        "#Column Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MgoHBf0TgMt"
      },
      "source": [
        "data=[(\"James\",\"Bond\",\"100\",None),\n",
        "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
        "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
        "      (\"Tom Brand\",None,\"400\",'M')] \n",
        "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
        "df=spark.createDataFrame(data,columns)\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG0QwcQPZ0cG"
      },
      "source": [
        "##alias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVwszUFETliZ"
      },
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "df2 = df.select(df.fname.alias(\"first_name\"), \\\n",
        "          df.lname.alias(\"last_name\"), \\\n",
        "          expr(\" fname ||','|| lname\").alias(\"fullName\") \\\n",
        "   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrWDbCaoHGmf"
      },
      "source": [
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z59pfSXW69uH"
      },
      "source": [
        "##asc, desc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doB2o9kR7FJS"
      },
      "source": [
        "df.sort(df.fname.asc()).show()\n",
        "df.sort(df.fname.desc()).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2k45bsDaCMp"
      },
      "source": [
        "##cast\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM5jNn_5Tpa3"
      },
      "source": [
        "df.select(df.fname,df.id.cast(\"int\")).printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxKmljfmIHuM"
      },
      "source": [
        "df.select(df.fname,df.id.cast(\"int\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRkTSTKPaNip"
      },
      "source": [
        "##between\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBH3gW7gTseP"
      },
      "source": [
        "df.filter(df.id.between(100,300)).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2ZbXJnNaRaA"
      },
      "source": [
        "##contains\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfSiL-b7Txda"
      },
      "source": [
        "df.filter(df.fname.contains(\"Cruise\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrZ2tA7LaWeX"
      },
      "source": [
        "##startswith, endswith\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH6oFC0v3Wv3"
      },
      "source": [
        "df.filter(df.fname.startswith(\"T\")).show()\n",
        "df.filter(df.fname.endswith(\"Cruise\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq5EIkfMadRw"
      },
      "source": [
        "##isNull & isNotNull\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x6sZXsTVBMU"
      },
      "source": [
        "df.filter(df.lname.isNull()).show()\n",
        "df.filter(df.lname.isNotNull()).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgmmKK7LamC5"
      },
      "source": [
        "##like , rlike\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfVAmDUNVCuA"
      },
      "source": [
        "df.select(df.fname,df.lname,df.id).filter(df.fname.like(\"%nn\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpvswJqAawuF"
      },
      "source": [
        "##substr\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_KnxiaKYwwc"
      },
      "source": [
        "#substr\n",
        "df.select(df.fname.substr(1,2).alias(\"substr\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq-cM6q_a6ik"
      },
      "source": [
        "##when & otherwise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz59FXSDa7UD"
      },
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "df.show()\n",
        "df.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\") \\\n",
        "              .when(df.gender==\"F\",\"Female\") \\\n",
        "              .when(df.gender==None ,\"\") \\\n",
        "              .otherwise(df.gender).alias(\"new_gender\") \\\n",
        "    ).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO8x1BxIbCAP"
      },
      "source": [
        "##isin\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr_pzCbaY4PE"
      },
      "source": [
        "li=[\"100\",\"200\"]\n",
        "df.select(df.fname,df.lname,df.id).filter(df.id.isin(li)).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQTa57SobHm2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0M0r23xY7Wj"
      },
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,ArrayType,MapType\n",
        "\n",
        "data=[((\"James\",\"Bond\"),[\"Java\",\"C#\"],{'hair':'black','eye':'brown'}),\n",
        "      ((\"Ann\",\"Varsa\"),[\".NET\",\"Python\"],{'hair':'brown','eye':'black'}),\n",
        "      ((\"Tom Cruise\",\"\"),[\"Python\",\"Scala\"],{'hair':'red','eye':'grey'}),\n",
        "      ((\"Tom Brand\",None),[\"Perl\",\"Ruby\"],{'hair':'black','eye':'blue'})]\n",
        "\n",
        "schema = StructType([\n",
        "        StructField('name', StructType([\n",
        "            StructField('fname', StringType(), True),\n",
        "            StructField('lname', StringType(), True)])),\n",
        "        StructField('languages', ArrayType(StringType()),True),\n",
        "        StructField('properties', MapType(StringType(),StringType()),True)\n",
        "     ])\n",
        "df=spark.createDataFrame(data,schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD6wGzZ5ZC2Y"
      },
      "source": [
        "#getItem()\n",
        "df.select(df.languages.getItem(1)).show()\n",
        "\n",
        "df.select(df.properties.getItem(\"hair\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T1jOcoNZG4v"
      },
      "source": [
        "#getField from Struct or Map\n",
        "df.select(df.properties.getField(\"hair\")).show()\n",
        "\n",
        "df.select(df.properties.getItem(\"hair\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq6xmFbVZKHf"
      },
      "source": [
        "#getField from Struct or Map\n",
        "df.select(df.properties.getField(\"hair\")).show()\n",
        "\n",
        "df.select(df.name.getField(\"fname\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vm8Ohq7ZV4I"
      },
      "source": [
        "#dropFields\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df.withColumn(\"name1\",col(\"name\").dropFields(\"fname\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX_KDgv4Zerd"
      },
      "source": [
        "#withField\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "df.withColumn(\"name\",df.name.withField(\"fname\",lit(\"AA\"))).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLFGHaKtZkRh"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "df = spark.createDataFrame([Row(a=Row(b=1, c=2))])\n",
        "df.show()\n",
        "df.withColumn('a', df['a'].withField('b', lit(3))).select('a.b').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLXNI2MOZpkn"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import col, lit\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "Row(a=Row(b=1, c=2, d=3, e=Row(f=4, g=5, h=6)))])\n",
        "df.show()\n",
        "df.withColumn('a', df['a'].dropFields('b')).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl0sXJ1sfRDV"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObK7MsiffBzx"
      },
      "source": [
        "#Column Operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5senxFicfNR6"
      },
      "source": [
        "data=[(\"James\",23),(\"Ann\",40)]\n",
        "df=spark.createDataFrame(data).toDF(\"name.fname\",\"gender\")\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbpzGdiifaaC"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df.select(col(\"`name.fname`\")).show()\n",
        "df.select(df[\"`name.fname`\"]).show()\n",
        "df.withColumn(\"new_col\",col(\"`name.fname`\").substr(1,2)).show()\n",
        "df.filter(col(\"`name.fname`\").startswith(\"J\")).show()\n",
        "new_cols=(column.replace('.', '_') for column in df.columns)\n",
        "df2 = df.toDF(*new_cols)\n",
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZsazL1Zfrf6"
      },
      "source": [
        "## Using DataFrame object\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewUb_kp5fsBn"
      },
      "source": [
        "df.select(df.gender).show()\n",
        "df.select(df[\"gender\"]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA_WdeHxf5f2"
      },
      "source": [
        "##Accessing column name with dot (with backticks)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Listrszf8v_"
      },
      "source": [
        "df.select(df[\"`name.fname`\"]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8MmnHcXgHda"
      },
      "source": [
        "##Using SQL col() function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BEbSDavf_na"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.select(col(\"gender\")).show()\n",
        "\n",
        "#Accessing column name with dot (with backticks)\n",
        "df.select(col(\"`name.fname`\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MasV8dHgODh"
      },
      "source": [
        "##Access struct column\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMxVOizEgMc2"
      },
      "source": [
        "data=[Row(name=\"James\",prop=Row(hair=\"black\",eye=\"blue\")),\n",
        "      Row(name=\"Ann\",prop=Row(hair=\"grey\",eye=\"black\"))]\n",
        "df=spark.createDataFrame(data)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8DQTZ8sgUsk"
      },
      "source": [
        "df.select(df.prop.hair).show()\n",
        "df.select(df.name,df.prop.hair).show()\n",
        "\n",
        "df.select(df[\"prop.hair\"]).show()\n",
        "df.select(col(\"prop.hair\")).show()\n",
        "\n",
        "df.select(col(\"prop.*\")).show()\n",
        "df.select(df.name,col(\"prop.*\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_MOSbMxgiRi"
      },
      "source": [
        "## Column operators\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ng95IGrgeME"
      },
      "source": [
        "data=[(100,2,1),(200,3,4),(300,4,4)]\n",
        "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\",\"col3\")\n",
        "df.show()\n",
        "\n",
        "df.select(df.col1 + df.col2).show()\n",
        "df.select(df.col1 - df.col2).show() \n",
        "df.select(df.col1 * df.col2).show()\n",
        "df.select(df.col1 / df.col2).show()\n",
        "df.select(df.col1 % df.col2).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLMc_gcjgeA0"
      },
      "source": [
        "df.show()\n",
        "df.select(df.col2 > df.col3).show()\n",
        "df.select(df.col2 < df.col3).show()\n",
        "df.select(df.col2 == df.col3).show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}